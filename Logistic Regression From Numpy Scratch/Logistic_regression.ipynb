{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e4bab7ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "50125ba1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Pregnancies     Glucose  BloodPressure  SkinThickness     Insulin  \\\n",
      "count   768.000000  768.000000     768.000000     768.000000  768.000000   \n",
      "mean      3.845052  120.894531      69.105469      20.536458   79.799479   \n",
      "std       3.369578   31.972618      19.355807      15.952218  115.244002   \n",
      "min       0.000000    0.000000       0.000000       0.000000    0.000000   \n",
      "25%       1.000000   99.000000      62.000000       0.000000    0.000000   \n",
      "50%       3.000000  117.000000      72.000000      23.000000   30.500000   \n",
      "75%       6.000000  140.250000      80.000000      32.000000  127.250000   \n",
      "max      17.000000  199.000000     122.000000      99.000000  846.000000   \n",
      "\n",
      "              BMI  DiabetesPedigreeFunction         Age     Outcome  \n",
      "count  768.000000                768.000000  768.000000  768.000000  \n",
      "mean    31.992578                  0.471876   33.240885    0.348958  \n",
      "std      7.884160                  0.331329   11.760232    0.476951  \n",
      "min      0.000000                  0.078000   21.000000    0.000000  \n",
      "25%     27.300000                  0.243750   24.000000    0.000000  \n",
      "50%     32.000000                  0.372500   29.000000    0.000000  \n",
      "75%     36.600000                  0.626250   41.000000    1.000000  \n",
      "max     67.100000                  2.420000   81.000000    1.000000  \n",
      "\n",
      "Missing values:\n",
      " Pregnancies                 0\n",
      "Glucose                     0\n",
      "BloodPressure               0\n",
      "SkinThickness               0\n",
      "Insulin                     0\n",
      "BMI                         0\n",
      "DiabetesPedigreeFunction    0\n",
      "Age                         0\n",
      "Outcome                     0\n",
      "dtype: int64\n",
      "\n",
      "Outcome distribution:\n",
      " Outcome\n",
      "0    500\n",
      "1    268\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shara\\AppData\\Local\\Temp\\ipykernel_13332\\1791572855.py:6: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].median(), inplace=True) #median not drop as very less values are missing and considered as 0 in dataset\n"
     ]
    }
   ],
   "source": [
    "file_path = \"C:/Users/shara/OneDrive/Desktop/ML ACTS/projects ml/Logistic Regression/diabetes (2).csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "print(df.describe())\n",
    "for col in ['Glucose', 'BloodPressure', 'SkinThickness', 'Insulin', 'BMI']:\n",
    "    df[col] = df[col].replace(0, np.nan)\n",
    "    df[col].fillna(df[col].median(), inplace=True) #median not drop as very less values are missing and considered as 0 in dataset\n",
    "print(\"\\nMissing values:\\n\", df.isnull().sum())\n",
    "print(\"\\nOutcome distribution:\\n\", df['Outcome'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a3abc1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set shape: (300, 9)\n",
      "Test set shape: (467, 9)\n",
      "X_train shape: (300, 8)\n",
      "y_train shape: (300,)\n",
      "X_test shape: (467, 8)\n",
      "y_test shape: (467,)\n"
     ]
    }
   ],
   "source": [
    "df_shuffled = df.sample(frac=1, random_state=42).reset_index(drop=True) #random_state for reproducibility , means if you run it again you will get same output even in other systems\n",
    "train = df_shuffled.iloc[:300]\n",
    "test = df_shuffled.iloc[300:767]\n",
    "print(f\"Train set shape: {train.shape}\")\n",
    "print(f\"Test set shape: {test.shape}\")\n",
    "\n",
    "X_train = train.iloc[:, :-1].values # numpy array\n",
    "y_train = train.iloc[:, -1].values  \n",
    "X_test = test.iloc[:, :-1].values  \n",
    "y_test = test.iloc[:, -1].values \n",
    "\n",
    "print(f\"X_train shape: {X_train.shape}\")\n",
    "print(f\"y_train shape: {y_train.shape}\")\n",
    "print(f\"X_test shape: {X_test.shape}\")\n",
    "print(f\"y_test shape: {y_test.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6c2f58a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#feature scaling (standardization) #this is z score normalization mean becomes 0 std dev becomes 1 \n",
    "#Features often have different units and magnitudes. For example, age might range 0â€“100, income could be in thousands or lakhs.\n",
    "#Models that use gradient descent, distance calculations, or regularization (e.g., linear regression(multiple features), logistic regression, SVMs, k-NN) perform better and train faster if the input features are on a similar scale.\n",
    "#Without scaling, features with larger ranges can dominate the learning process or cause numerical instability.\n",
    "train_mean = np.mean(X_train, axis=0)\n",
    "train_std = np.std(X_train, axis=0)#axis=0 means for each feature =x column\n",
    "X_train_scaled = (X_train - train_mean) / train_std\n",
    "X_test_scaled = (X_test - train_mean) / train_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1fe5f32",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegression:\n",
    "    def __init__(self, learning_rate=0.01, n_iterations=1000):\n",
    "        self.learning_rate = learning_rate\n",
    "        self.n_iterations = n_iterations\n",
    "        self.weights = None\n",
    "        self.bias = None\n",
    "        self.loss_curve = []\n",
    "\n",
    "    def sigmoid(self, z):\n",
    "        return 1 / (1 + np.exp(-z))\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.m, self.n = X.shape      # m = training samples(rows), n = features (columns)\n",
    "        self.weights = np.zeros(self.n)\n",
    "        self.bias = 0\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        for i in range(self.n_iterations):\n",
    "            self.update_weights()\n",
    "\n",
    "    def update_weights(self):\n",
    "        y_hat = self.sigmoid(np.dot(self.X, self.weights) + self.bias)  #y_hat is sigmoid function formula value (z)\n",
    "        dw = (1 / self.m) * np.dot(self.X.T, (y_hat - self.y)) # self.X.T is now(n,m) so that dot product gives (n,) weights which is 1 dimension \n",
    "        db = (1 / self.m) * np.sum(y_hat - self.y)   # 1/m to avg over all samples / total no. of rows \n",
    "        self.weights -= self.learning_rate * dw\n",
    "        self.bias -= self.learning_rate * db\n",
    "\n",
    "    def predict(self, X):\n",
    "        y_pred = self.sigmoid(np.dot(X, self.weights) + self.bias)\n",
    "        y_pred = np.where(y_pred >= 0.5, 1, 0) #will make the y value either be 1 or 0 seperator 0.5\n",
    "        return y_pred\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e83464e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression(learning_rate=0.01, n_iterations=1000)\n",
    "model.fit(X_train_scaled, y_train)\n",
    "y_pred_train = model.predict(X_train_scaled)\n",
    "y_pred_test = model.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ed7de28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 78.33%\n",
      "Test Accuracy: 75.16%\n"
     ]
    }
   ],
   "source": [
    "train_acc = np.mean(y_pred_train == y_train)\n",
    "test_acc = np.mean(y_pred_test == y_test)\n",
    "#means if prediction is 0 and same as actual (0 or same for 1) then its correct prediction\n",
    "print(f\"Train Accuracy: {train_acc * 100:.2f}%\")\n",
    "print(f\"Test Accuracy: {test_acc * 100:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
