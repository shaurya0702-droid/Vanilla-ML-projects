# Vanilla Machine Learning Projects üß†‚öôÔ∏è

This repository is a comprehensive collection of **vanilla machine learning projects**, with a strong focus on **building algorithms from scratch using NumPy** and understanding the **core mathematics and intuition behind ML models**.

The goal of this repo is **learning-first**, not just using libraries as black boxes.

---

## üîç What I Focused On

- Implementing ML algorithms **from scratch using NumPy**
- Understanding the **math, intuition, and workflow** behind each model
- Comparing **from-scratch implementations vs library-based approaches**
- Keeping the code **clean, modular, and readable**
- Deploying one end-to-end ML project using **Streamlit**

---

## üìÇ Projects Included

### 1Ô∏è‚É£ Linear Regression (From NumPy Scratch)
**Folder:** `Linear-Regression-From-Numpy-Scratch`

- Implemented Linear Regression without using `sklearn`
- Covered:
  - Cost function (MSE)
  - Gradient Descent
  - Weight & bias updates
- Focused on understanding **why gradient descent works**

---

### 2Ô∏è‚É£ Logistic Regression (From NumPy Scratch)
**Folder:** `Logistic-Regression-From-Numpy-Scratch`

- Binary classification from scratch
- Implemented:
  - Sigmoid activation
  - Binary Cross-Entropy loss
  - Gradient Descent
- Focused on decision boundaries and probability interpretation

---

### 3Ô∏è‚É£ Mini Linear Algebra Library (From NumPy Scratch)
**Folder:** `Mini-Linear-Algebra-From-Numpy-Scratch`

- Built a small utility library for:
  - Vector operations
  - Matrix operations
  - Dot products, norms, projections
- Strengthened foundations required for ML & DL

---

### 4Ô∏è‚É£ Principal Component Analysis (PCA) (From NumPy Scratch)
**Folder:** `PCA-From-Numpy-Scratch`

- Implemented PCA step-by-step:
  - Mean centering
  - Covariance matrix
  - Eigenvalues & eigenvectors
- Used for **dimensionality reduction**
- Focused on variance preservation intuition

---

### 5Ô∏è‚É£ Support Vector Machine (From NumPy Scratch)
**Folder:** `SVM-From-Numpy-Scratch`

- Implemented a basic SVM classifier
- Focused on:
  - Maximum margin intuition
  - Hinge loss
  - Role of regularization
- Helped understand why SVMs are powerful for small datasets

---

### 6Ô∏è‚É£ Vector Visualization & Operations
**Folder:** `Vector-Visualization-From-Numpy-Scratch`

- Visualized vectors, projections, and transformations
- Used matplotlib to build geometric intuition
- Helped connect **math ‚Üí geometry ‚Üí ML**

---

### 7Ô∏è‚É£ Random Forest with Streamlit (Deployment Project)
**Folder:** `Random-Forest-with-Streamlit`

- Used `sklearn` Random Forest model
- Built an **end-to-end ML pipeline**
- Deployed using **Streamlit**
- Focused on:
  - Model training
  - Pickling
  - User input ‚Üí prediction workflow

---

### 8Ô∏è‚É£ Boosting Models Comparison
**Folder:** `XGBoost-CatBoost-GradientBoosting-Comparison`

- Compared boosting algorithms:
  - Gradient Boosting
  - XGBoost
  - CatBoost
- Focused on:
  - Performance comparison
  - Bias‚Äìvariance tradeoff
  - When to use which boosting model

---

## üß† Key Takeaways

- Built **strong ML fundamentals**
- Learned ML beyond just calling libraries
- Developed intuition for **loss functions, optimization, and model behavior**
- Understood **when and why** to use specific algorithms

---

## üõ†Ô∏è Tech Stack Used

- Python
- NumPy
- Pandas
- Matplotlib
- Scikit-learn
- Streamlit

---

## üöÄ Future Plans

- Add more deployment projects
- Extend from vanilla ML to deep learning
- Improve visualizations and documentation

---

üìå *This repository represents my journey of understanding machine learning from the ground up.*
